{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create logs folder\n",
    "os.mkdir('logs')\n",
    "os.mkdir('dags')\n",
    "\n",
    "#Create .env\n",
    "env_file_path = \".env\"\n",
    "env_content = \"\"\"\n",
    "AIRFLOW_UID=501\n",
    "AIRFLOW_GID=0\n",
    "\"\"\"\n",
    "with open(env_file_path, \"w\") as env_file:\n",
    "    env_file.write(env_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your data folder inside the dags folder\n",
    "\n",
    "Make sure that the folder is called data and that every folder inside is called sf_3 or the respective scale factor number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to airflow-init-1\n",
      "airflow-init-1  | \n",
      "airflow-init-1  | DB: postgresql+psycopg2://airflow:***@postgres/airflow\n",
      "airflow-init-1  | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:00,573\u001b[0m] {\u001b[34mdb.py:\u001b[0m1410} INFO\u001b[0m - Creating tables\u001b[0m\n",
      "airflow-init-1  | Upgrades done\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:13,838\u001b[0m] {\u001b[34mmanager.py:\u001b[0m585} INFO\u001b[0m - Removed Permission menu access on Permissions to role Admin\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:13,890\u001b[0m] {\u001b[34mmanager.py:\u001b[0m543} INFO\u001b[0m - Removed Permission View: menu_access on Permissions\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:14,069\u001b[0m] {\u001b[34mmanager.py:\u001b[0m508} INFO\u001b[0m - Created Permission View: menu access on Permissions\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:14,087\u001b[0m] {\u001b[34mmanager.py:\u001b[0m568} INFO\u001b[0m - Added Permission menu access on Permissions to role Admin\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:22,062\u001b[0m] {\u001b[34mproviders_manager.py:\u001b[0m218} INFO\u001b[0m - Optional provider feature disabled when importing 'airflow.providers.google.leveldb.hooks.leveldb.LevelDBHook' from 'apache-airflow-providers-google' package\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:27,646\u001b[0m] {\u001b[34mproviders_manager.py:\u001b[0m218} INFO\u001b[0m - Optional provider feature disabled when importing 'airflow.providers.google.leveldb.hooks.leveldb.LevelDBHook' from 'apache-airflow-providers-google' package\u001b[0m\n",
      "airflow-init-1  | airflow already exist in the db\n",
      "airflow-init-1  | 2.3.0\n",
      "\n",
      "\u001b[Kairflow-init-1 exited with code 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Run the docker-compose command\n",
    "    result = subprocess.run([\"docker-compose\", \"up\", \"airflow-init\"], capture_output=True, text=True, check=True)\n",
    "    \n",
    "    # Print the output\n",
    "    print(result.stdout)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    print(f\"Error Output: {e.stderr}\")\n",
    "    \n",
    "#This cell takes like 3-4 mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "# Check the operating system\n",
    "if platform.system() == \"Linux\":\n",
    "    # Open a new terminal window and run docker-compose up (using gnome-terminal)\n",
    "    subprocess.run([\"gnome-terminal\", \"--\", \"bash\", \"-c\", \"docker-compose up; exec bash\"])\n",
    "\n",
    "elif platform.system() == \"Darwin\":  # macOS\n",
    "    # Open a new terminal window and run docker-compose up (using osascript)\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell app \"Terminal\" to do script \"docker-compose up\"'])\n",
    "\n",
    "elif platform.system() == \"Windows\":\n",
    "    # Open a new cmd window and run docker-compose up\n",
    "    subprocess.run([\"start\", \"cmd\", \"/K\", \"docker-compose up\"], shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL MUST BE RUN ONLY ONCE \n",
    "\n",
    "# Check the operating system\n",
    "if platform.system() == \"Linux\":\n",
    "    # Open a new terminal window and run docker-compose run airflow-cli webserver\n",
    "    subprocess.run([\"gnome-terminal\", \"--\", \"bash\", \"-c\", \"docker-compose run airflow-cli webserver; exec bash\"])\n",
    "\n",
    "# Check the operating system\n",
    "if platform.system() == \"Darwin\":  # macOS\n",
    "    # Open a new terminal window and run docker-compose run airflow-cli webserver\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell app \"Terminal\" to do script \"docker-compose run airflow-cli webserver\"'])\n",
    "\n",
    "# Check the operating system\n",
    "if platform.system() == \"Windows\":\n",
    "    # Open a new cmd window and run docker-compose run airflow-cli webserver\n",
    "    subprocess.run([\"start\", \"cmd\", \"/K\", \"docker-compose run airflow-cli webserver\"], shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on every time you need to open Airflow again, just run docker-compose up inside src folder\n",
    "\n",
    "Open localhost:8080\n",
    "\n",
    "User: airflow\n",
    "Password: airflow\n",
    "\n",
    "Open the CLI and click on Admin/Connections\n",
    "\n",
    "Create a new Postgres connection for every SF you want to run\n",
    "\n",
    "Connection Id: postgres_SF (change SF for the number)\n",
    "Connection Type: Postgres\n",
    "Host: host.docker.internal\n",
    "Schema: sf_SF (change SF for the number)\n",
    "Login: postgres\n",
    "Password: (Your Postgres password)\n",
    "Port: (Your Postgres port)\n",
    "\n",
    "Go to pgAdmin and create for every SF a schema/database and call them sf_SF (change SF for the number)\n",
    "\n",
    "Run create_sf.ipynb for each sf you have in your data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
