{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/josub/Desktop/BDMA/Brussels/Data_Warehouses/tpcdi-benchmark-postgres-josu/tpcdi-benchmark-postgres-josu/src/dags/data/sf3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#SET VARIABLES\n",
    "SF=3\n",
    "PATH=os.getcwd().replace(\"\\\\\", \"/\")+'/dags/data/sf'+str(SF)\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create logs folder\n",
    "os.mkdir('logs')\n",
    "\n",
    "#Create .env\n",
    "env_file_path = \".env\"\n",
    "env_content = \"\"\"\n",
    "AIRFLOW_UID=501\n",
    "AIRFLOW_GID=0\n",
    "\"\"\"\n",
    "with open(env_file_path, \"w\") as env_file:\n",
    "    env_file.write(env_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to airflow-init-1\n",
      "airflow-init-1  | \n",
      "airflow-init-1  | DB: postgresql+psycopg2://airflow:***@postgres/airflow\n",
      "airflow-init-1  | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:00,573\u001b[0m] {\u001b[34mdb.py:\u001b[0m1410} INFO\u001b[0m - Creating tables\u001b[0m\n",
      "airflow-init-1  | Upgrades done\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:13,838\u001b[0m] {\u001b[34mmanager.py:\u001b[0m585} INFO\u001b[0m - Removed Permission menu access on Permissions to role Admin\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:13,890\u001b[0m] {\u001b[34mmanager.py:\u001b[0m543} INFO\u001b[0m - Removed Permission View: menu_access on Permissions\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:14,069\u001b[0m] {\u001b[34mmanager.py:\u001b[0m508} INFO\u001b[0m - Created Permission View: menu access on Permissions\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:14,087\u001b[0m] {\u001b[34mmanager.py:\u001b[0m568} INFO\u001b[0m - Added Permission menu access on Permissions to role Admin\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:22,062\u001b[0m] {\u001b[34mproviders_manager.py:\u001b[0m218} INFO\u001b[0m - Optional provider feature disabled when importing 'airflow.providers.google.leveldb.hooks.leveldb.LevelDBHook' from 'apache-airflow-providers-google' package\u001b[0m\n",
      "airflow-init-1  | [\u001b[34m2024-12-17 18:10:27,646\u001b[0m] {\u001b[34mproviders_manager.py:\u001b[0m218} INFO\u001b[0m - Optional provider feature disabled when importing 'airflow.providers.google.leveldb.hooks.leveldb.LevelDBHook' from 'apache-airflow-providers-google' package\u001b[0m\n",
      "airflow-init-1  | airflow already exist in the db\n",
      "airflow-init-1  | 2.3.0\n",
      "\n",
      "\u001b[Kairflow-init-1 exited with code 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Run the docker-compose command\n",
    "    result = subprocess.run([\"docker-compose\", \"up\", \"airflow-init\"], capture_output=True, text=True, check=True)\n",
    "    \n",
    "    # Print the output\n",
    "    print(result.stdout)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    print(f\"Error Output: {e.stderr}\")\n",
    "    \n",
    "#This cell takes like 3-4 mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import platform\n",
    "\n",
    "# Check the operating system\n",
    "if platform.system() == \"Linux\":\n",
    "    # Open a new terminal window and run docker-compose up (using gnome-terminal)\n",
    "    subprocess.run([\"gnome-terminal\", \"--\", \"bash\", \"-c\", \"docker-compose up; exec bash\"])\n",
    "\n",
    "elif platform.system() == \"Darwin\":  # macOS\n",
    "    # Open a new terminal window and run docker-compose up (using osascript)\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell app \"Terminal\" to do script \"docker-compose up\"'])\n",
    "\n",
    "elif platform.system() == \"Windows\":\n",
    "    # Open a new cmd window and run docker-compose up\n",
    "    subprocess.run([\"start\", \"cmd\", \"/K\", \"docker-compose up\"], shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL MUST BE RUN ONLY ONCE \n",
    "\n",
    "# Check the operating system\n",
    "if platform.system() == \"Linux\":\n",
    "    # Open a new terminal window and run docker-compose run airflow-cli webserver\n",
    "    subprocess.run([\"gnome-terminal\", \"--\", \"bash\", \"-c\", \"docker-compose run airflow-cli webserver; exec bash\"])\n",
    "\n",
    "# Check the operating system\n",
    "if platform.system() == \"Darwin\":  # macOS\n",
    "    # Open a new terminal window and run docker-compose run airflow-cli webserver\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell app \"Terminal\" to do script \"docker-compose run airflow-cli webserver\"'])\n",
    "\n",
    "# Check the operating system\n",
    "if platform.system() == \"Windows\":\n",
    "    # Open a new cmd window and run docker-compose run airflow-cli webserver\n",
    "    subprocess.run([\"start\", \"cmd\", \"/K\", \"docker-compose run airflow-cli webserver\"], shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on every time you need to open Airflow again, just run docker-compose up\n",
    "\n",
    "Open localhost:8080\n",
    "\n",
    "User: airflow\n",
    "Password: airflow\n",
    "\n",
    "Keep running the cells to generate the scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"dags/sf_\"+str(SF)+\"/staging_data_commands.sql\"\n",
    "\n",
    "# Generate SQL Statements\n",
    "with open(output_file, \"w\") as file:\n",
    "        sql = f\"\"\"COPY staging.batchdate FROM '{PATH}/Batch1/BatchDate.txt';\\n\n",
    "COPY staging.cashtransaction FROM '{PATH}/Batch1/CashTransaction.txt' delimiter '|';\\n\n",
    "COPY staging.dailymarket FROM '{PATH}/Batch1/DailyMarket.txt' delimiter '|';\\n\n",
    "COPY staging.date FROM '{PATH}/Batch1/Date.txt' delimiter '|';\\n\n",
    "COPY staging.holdinghistory FROM '{PATH}/Batch1/HoldingHistory.txt' delimiter '|';\\n\n",
    "COPY staging.hr FROM '{PATH}/Batch1/HR.csv' delimiter ',' CSV;\\n\n",
    "COPY staging.industry FROM '{PATH}/Batch1/Industry.txt' delimiter '|';\\n\n",
    "COPY staging.prospect FROM '{PATH}/Batch1/Prospect.csv' delimiter ',' CSV;\\n\n",
    "COPY staging.statustype FROM '{PATH}/Batch1/StatusType.txt' delimiter '|';\\n\n",
    "COPY staging.taxrate FROM '{PATH}/Batch1/TaxRate.txt' delimiter '|';\\n\n",
    "COPY staging.time FROM '{PATH}/Batch1/Time.txt' delimiter '|';\\n\n",
    "COPY staging.tradehistory FROM '{PATH}/Batch1/TradeHistory.txt' delimiter '|';\\n\n",
    "COPY staging.trade FROM '{PATH}/Batch1/Trade.txt' delimiter '|' null as '';\\n\n",
    "COPY staging.tradetype FROM '{PATH}/Batch1/TradeType.txt' delimiter '|';\\n\n",
    "COPY staging.watchhistory FROM '{PATH}/Batch1/WatchHistory.txt' delimiter '|';\\n\n",
    "COPY staging.audit FROM '{PATH}/Batch1_audit.csv' DELIMITER ',' HEADER CSV NULL AS '';\\n       \n",
    "\"\"\"\n",
    "\n",
    "        file.write(sql)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"dags/sf_\"+str(SF)+\"/staging_finwire_load1.sql\"\n",
    "\n",
    "# Generate SQL Statements\n",
    "with open(output_file, \"w\") as file:\n",
    "    for i in range(1967,2017):\n",
    "        for j in range(4):\n",
    "            sql = f\"COPY staging.finwire FROM '{PATH}/Batch1/FINWIRE{i}Q{j+1}';\\n\"\n",
    "            file.write(sql)\n",
    "    sql = f\"COPY staging.finwire FROM '{PATH}/Batch1/FINWIRE2017Q1';\\n\"\n",
    "    file.write(sql)\n",
    "    sql = f\"COPY staging.finwire FROM '{PATH}/Batch1/FINWIRE2017Q2';\\n\"\n",
    "    file.write(sql)\n",
    "    sql = f\"COPY staging.finwire FROM '{PATH}/Batch1/FINWIRE2017Q3';\\n\"\n",
    "    file.write(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
