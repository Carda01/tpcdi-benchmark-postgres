{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT THE SIZE OF THE NEW SF THAT YOU WANT TO CREATE\n",
    "SF=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alfio/projects/tpcdi-benchmark-postgres/src/dags/data/sf_5\n"
     ]
    }
   ],
   "source": [
    "#SET VARIABLES\n",
    "PATH=os.getcwd().replace(\"\\\\\", \"/\")+'/dags/data/sf_'+str(SF)\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dags_temp/dags_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m dags_templates_path \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdags_temp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m dags_sf_path \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdags\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSF\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdags_templates_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdags_temp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdags_sf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dags_sf_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_historical_load_etl_dag.py\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      7\u001b[0m     content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/shutil.py:555\u001b[0m, in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Recursively copy a directory tree and return the destination directory.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03mdirs_exist_ok dictates whether to raise an exception in case dst or any\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    552\u001b[0m \n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutil.copytree\u001b[39m\u001b[38;5;124m\"\u001b[39m, src, dst)\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m itr:\n\u001b[1;32m    556\u001b[0m     entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itr)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _copytree(entries\u001b[38;5;241m=\u001b[39mentries, src\u001b[38;5;241m=\u001b[39msrc, dst\u001b[38;5;241m=\u001b[39mdst, symlinks\u001b[38;5;241m=\u001b[39msymlinks,\n\u001b[1;32m    558\u001b[0m                  ignore\u001b[38;5;241m=\u001b[39mignore, copy_function\u001b[38;5;241m=\u001b[39mcopy_function,\n\u001b[1;32m    559\u001b[0m                  ignore_dangling_symlinks\u001b[38;5;241m=\u001b[39mignore_dangling_symlinks,\n\u001b[1;32m    560\u001b[0m                  dirs_exist_ok\u001b[38;5;241m=\u001b[39mdirs_exist_ok)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dags_temp/dags_temp'"
     ]
    }
   ],
   "source": [
    "p = Path('.')\n",
    "dags_templates_path = p / 'dags_temp'\n",
    "dags_sf_path = p / 'dags' / f'sf_{SF}'\n",
    "\n",
    "shutil.copytree(dags_templates_path , dags_sf_path)\n",
    "with open(dags_sf_path / 'full_historical_load_etl_dag.py', \"r\") as file:\n",
    "    content = file.read()\n",
    "modified_content = content.replace('INPUT_SF', str(SF))\n",
    "with open(dags_sf_path / 'full_historical_load_etl_dag.py', \"w\") as file:\n",
    "    file.write(modified_content)\n",
    "    \n",
    "with open(dags_sf_path / 'incremental_first_dag.py', \"r\") as file:\n",
    "    content = file.read()\n",
    "modified_content = content.replace('INPUT_SF', str(SF))\n",
    "with open(dags_sf_path / 'incremental_first_dag.py', \"w\") as file:\n",
    "    file.write(modified_content)\n",
    "\n",
    "with open(dags_sf_path / 'incremental_second_dag.py', \"r\") as file:\n",
    "    content = file.read()\n",
    "modified_content = content.replace('INPUT_SF', str(SF))\n",
    "with open(dags_sf_path / 'incremental_second_dag.py', \"w\") as file:\n",
    "    file.write(modified_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = dags_sf_path / 'staging_data_commands.sql'\n",
    "\n",
    "# Generate SQL Statements\n",
    "with open(output_file, \"w\") as file:\n",
    "        sql = f\"\"\"COPY staging.batchdate FROM '{PATH}/Batch1/BatchDate.txt';\\n\n",
    "COPY staging.cashtransaction FROM '{PATH}/Batch1/CashTransaction.txt' delimiter '|';\\n\n",
    "COPY staging.dailymarket FROM '{PATH}/Batch1/DailyMarket.txt' delimiter '|';\\n\n",
    "COPY staging.date FROM '{PATH}/Batch1/Date.txt' delimiter '|';\\n\n",
    "COPY staging.holdinghistory FROM '{PATH}/Batch1/HoldingHistory.txt' delimiter '|';\\n\n",
    "COPY staging.hr FROM '{PATH}/Batch1/HR.csv' delimiter ',' CSV;\\n\n",
    "COPY staging.industry FROM '{PATH}/Batch1/Industry.txt' delimiter '|';\\n\n",
    "COPY staging.prospect FROM '{PATH}/Batch1/Prospect.csv' delimiter ',' CSV;\\n\n",
    "COPY staging.statustype FROM '{PATH}/Batch1/StatusType.txt' delimiter '|';\\n\n",
    "COPY staging.taxrate FROM '{PATH}/Batch1/TaxRate.txt' delimiter '|';\\n\n",
    "COPY staging.time FROM '{PATH}/Batch1/Time.txt' delimiter '|';\\n\n",
    "COPY staging.tradehistory FROM '{PATH}/Batch1/TradeHistory.txt' delimiter '|';\\n\n",
    "COPY staging.trade FROM '{PATH}/Batch1/Trade.txt' delimiter '|' null as '';\\n\n",
    "COPY staging.tradetype FROM '{PATH}/Batch1/TradeType.txt' delimiter '|';\\n\n",
    "COPY staging.watchhistory FROM '{PATH}/Batch1/WatchHistory.txt' delimiter '|';\\n\n",
    "COPY staging.audit FROM '{PATH}/Batch1_audit.csv' DELIMITER ',' HEADER CSV NULL AS '';\\n       \n",
    "\"\"\"\n",
    "\n",
    "        file.write(sql)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = dags_sf_path / 'staging_finwire_load1.sql'\n",
    "\n",
    "# Generate SQL Statements\n",
    "with open(output_file, \"w\") as file:\n",
    "    for i in range(1967,2017):\n",
    "        for j in range(4):\n",
    "            sql = f\"COPY staging.finwire FROM '{PATH}/Batch1/FINWIRE{i}Q{j+1}';\\n\"\n",
    "            file.write(sql)\n",
    "    sql = f\"COPY staging.finwire FROM '{PATH}/Batch1/FINWIRE2017Q1';\\n\"\n",
    "    file.write(sql)\n",
    "    sql = f\"COPY staging.finwire FROM '{PATH}/Batch1/FINWIRE2017Q2';\\n\"\n",
    "    file.write(sql)\n",
    "    sql = f\"COPY staging.finwire FROM '{PATH}/Batch1/FINWIRE2017Q3';\\n\"\n",
    "    file.write(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = dags_sf_path / \"load_staging_customermgmt_db.sql\"\n",
    "\n",
    "# Generate SQL Statements\n",
    "with open(output_file, \"w\") as file:\n",
    "    sql = f\"COPY staging.customermgmt FROM '{PATH}/Batch1/CustomerMgmt.csv' DELIMITER ',' HEADER CSV NULL AS '';\\n\"\n",
    "    file.write(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = dags_sf_path / \"incremental_update\" / \"load_staging_b3.sql\"\n",
    "\n",
    "# Generate SQL Statements\n",
    "with open(output_file, \"w\") as file:\n",
    "    sql = f\"\"\"COPY staging.batchdate FROM '{PATH}/Batch3/BatchDate.txt';\n",
    "COPY staging.cashtransaction_b2 FROM '{PATH}/Batch3/CashTransaction.txt' delimiter '|';\n",
    "COPY staging.dailymarket_b2 FROM '{PATH}/Batch3/DailyMarket.txt' delimiter '|';\n",
    "COPY staging.holdinghistory_b2 FROM '{PATH}/Batch3/HoldingHistory.txt' delimiter '|';\n",
    "COPY staging.prospect FROM '{PATH}/Batch3/Prospect.csv' delimiter ',' CSV;\n",
    "COPY staging.watchhistory_b2 FROM '{PATH}/Batch3/WatchHistory.txt' delimiter '|';\n",
    "COPY staging.trade_b2 FROM '{PATH}/Batch3/Trade.txt' delimiter '|' null as '';\n",
    "COPY staging.customer FROM '{PATH}/Batch3/Customer.txt' delimiter '|' null as '';\n",
    "COPY staging.account FROM '{PATH}/Batch3/Account.txt' delimiter '|' null as '';\"\"\"\n",
    "    file.write(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = dags_sf_path / \"incremental_update\" / \"load_staging.sql\"\n",
    "\n",
    "# Generate SQL Statements\n",
    "with open(output_file, \"w\") as file:\n",
    "    sql = f\"\"\"COPY staging.batchdate FROM '{PATH}/Batch2/BatchDate.txt';\n",
    "COPY staging.cashtransaction_b2 FROM '{PATH}/Batch2/CashTransaction.txt' delimiter '|';\n",
    "COPY staging.dailymarket_b2 FROM '{PATH}/Batch2/DailyMarket.txt' delimiter '|';\n",
    "COPY staging.holdinghistory_b2 FROM '{PATH}/Batch2/HoldingHistory.txt' delimiter '|';\n",
    "COPY staging.prospect FROM '{PATH}/Batch2/Prospect.csv' delimiter ',' CSV;\n",
    "COPY staging.watchhistory_b2 FROM '{PATH}/Batch2/WatchHistory.txt' delimiter '|';\n",
    "COPY staging.trade_b2 FROM '{PATH}/Batch2/Trade.txt' delimiter '|' null as '';\n",
    "COPY staging.customer FROM '{PATH}/Batch2/Customer.txt' delimiter '|' null as '';\n",
    "COPY staging.account FROM '{PATH}/Batch2/Account.txt' delimiter '|' null as '';\"\"\"\n",
    "    file.write(sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
